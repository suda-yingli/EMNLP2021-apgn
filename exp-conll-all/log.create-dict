read config from config.txt
Loaded config file successfully.
is_test 0
is_train 1
device-x cpu
device cuda:5
dict_dir ./
word_freq_cutoff 1
model_dir ./
ext_word_emb_full_path /data1/yli/paser/domain-dependency-parsers/data/giga.bin
ext_word_dict_full_path /data1/yli/paser/domain-dependency-parsers/data/extwords.txt
inst_num_max -1
max_bucket_num 80
sent_num_one_batch 200
word_num_one_batch 5000
is_shared_lstm 1
is_gate_lstm 1
is_diff_loss 1
is_domain_emb 0
is_adversary 1
is_multi 0
is_charlstm 1
model_eval_num 0
data_dir /data1/yli/paser/domain-dependency-parsers/data/PC
train_files /data1/yli/paser/domain-dependency-parsers/data/BC/train-bc.conll:/data1/yli/paser/domain-dependency-parsers/data/PB/train-content.conll:/data1/yli/paser/domain-dependency-parsers/data/ZX/train-zx.conll
dev_files /data1/yli/paser/domain-dependency-parsers/data/PC/dev-comment.conll
test_files /data1/yli/paser/domain-dependency-parsers/data/PC/test-comment.conll
unlabel_train_files /data1/yli/paser/domain-dependency-parsers/data/Unlabeled-pos/comment-unlabel-pos.conll
is_dictionary_exist 0
train_max_eval_num 1000
save_model_after_eval_num 1
train_stop_after_eval_num_no_improve 100
eval_every_update_step_num 229
lstm_layer_num 3
word_emb_dim 100
tag_emb_dim 100
domain_emb_dim 12
domain_size 4
emb_dropout_ratio 0.33
lstm_hidden_dim 400
lstm_input_dropout_ratio 0.33
lstm_hidden_dropout_ratio_for_next_timestamp 0.33
mlp_output_dim_arc 500
mlp_output_dim_rel 100
mlp_input_dropout_ratio 0.33
mlp_output_dropout_ratio 0.33
learning_rate 2e-3
decay .75
decay_steps 5000
beta_1 .9
beta_2 .9
epsilon 1e-12
clip 5.0
adversary_lambda_loss 1
diff_bate_loss 0.01
random_seeds =  [1572938682, 687671153, 604898817, 591143824]
self._file_name_short parsers_data_BC_train-bc.conll
self._domain_id 1
Reading parsers_data_BC_train-bc.conll done: 16339 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 1435 10 8 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 1886 12 10 8
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 2007 14 11 18
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 1054 15 6 29
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 1008 16 6 35
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  5 1017 17 6 41
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  6 1082 18 6 47
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  7 1050 19 6 53
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  8 1032 20 6 59
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  9 1003 21 6 65
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  10 762 22 4 71
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  11 779 23 4 75
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  12 719 24 4 79
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  13 677 25 4 83
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  14 828 31 5 87
parsers_data_BC_train-bc.conll can provide 92 batches in total with 15 buckets
self._file_name_short rs_data_PB_train-content.conll
self._domain_id 3
Reading rs_data_PB_train-content.conll done: 5129 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 1088 10 6 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 862 13 5 6
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 887 16 5 11
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 605 18 4 16
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 606 20 4 20
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  5 602 23 4 24
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  6 479 26 3 28
rs_data_PB_train-content.conll can provide 31 batches in total with 7 buckets
self._file_name_short parsers_data_ZX_train-zx.conll
self._domain_id 4
Reading parsers_data_ZX_train-zx.conll done: 1645 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 635 22 4 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 353 29 2 4
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 290 36 2 6
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 232 43 2 8
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 135 54 1 10
parsers_data_ZX_train-zx.conll can provide 11 batches in total with 5 buckets
self._file_name_short -pos_comment-unlabel-pos.conll
self._domain_id 2
Reading -pos_comment-unlabel-pos.conll done: 16339 instances
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  0 1894 7 10 0
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  1 2203 9 12 10
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  2 1521 11 8 22
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  3 1164 13 6 30
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  4 957 15 5 36
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  5 893 17 5 41
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  6 994 19 5 46
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  7 927 21 5 51
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  8 477 22 3 56
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  9 873 24 5 59
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  10 793 26 4 64
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  11 735 28 4 68
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  12 604 30 4 72
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  13 508 32 3 76
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  14 401 34 3 79
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  15 353 36 3 82
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  16 290 38 2 85
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  17 318 41 3 87
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  18 270 45 2 90
i, inst_num, max_len, batch_num_to_provide, batch_num_total =  19 164 84 3 92
-pos_comment-unlabel-pos.conll can provide 95 batches in total with 20 buckets
create dict...
max_char: 32
max_char: 6
max_char: 7
Traceback (most recent call last):
  File "../src/main.py", line 37, in <module>
    parser.run()
  File "/data1/yli/paser/domain-dependency-parsers/multi-domain-dependency-parser/unsupervised-adversary-models/classifier-domain-adv/word-level/cpm-domainclassifier-models/domain-classifier-cpm/unlabel-tgtdomain/12-cpm-domain-classifier-domainembedding/src/parser.py", line 174, in run
    self.save_dictionaries(self._conf.dict_dir)
  File "/data1/yli/paser/domain-dependency-parsers/multi-domain-dependency-parser/unsupervised-adversary-models/classifier-domain-adv/word-level/cpm-domainclassifier-models/domain-classifier-cpm/unlabel-tgtdomain/12-cpm-domain-classifier-domainembedding/src/parser.py", line 604, in save_dictionaries
    assert os.path.exists(path) is False
AssertionError
